{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFFFFFFFFFFFRFFF\n",
      "FFFFFFFFFHFFFFFR\n",
      "FFFFFFFFFFFFRFFH\n",
      "FFFFFFFFFFFFFFFR\n",
      "FFHFFFFFFFFFFFFF\n",
      "FFFFFFFFFFFFFFFF\n",
      "FFFFFFFFFFFFFFFF\n",
      "FFFFFFRFFFFFRFFF\n",
      "FFFFFFHFFFFFFFFF\n",
      "FFFFFFFFFFFFFFFF\n",
      "FFFFFFFFFFRFFFRF\n",
      "FFFFFRFFFFFFFFFF\n",
      "FFHFFFFHFHFHFFFF\n",
      "FFFFFFFFFFFFFFFF\n",
      "FFFFFFFFFHFFFFFF\n",
      "FFFFFFHFFFRFFFFG\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class CustomFrozenLakeEnv(gym.Env):\n",
    "    def __init__(self, size=16, num_holes=10, num_specials=10, start_point=(0, 0), end_point=None):\n",
    "        assert size >= 4, \"Size of the gym should be at least 4x4\"\n",
    "        assert num_holes < size**2 - 2, \"Number of holes should be less than total available spaces\"\n",
    "\n",
    "        self.size = size\n",
    "        self.num_holes = num_holes\n",
    "        self.num_specials = num_specials\n",
    "        self.start_point = start_point\n",
    "        self.end_point = end_point if end_point is not None else (size - 1, size - 1)\n",
    "\n",
    "        self.observation_space = spaces.Discrete(size**2)\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "\n",
    "        self.desc = self.generate_random_environment()\n",
    "        self.state = self.get_state_from_point(self.start_point)\n",
    "\n",
    "    def generate_random_environment(self):\n",
    "        desc = np.full((self.size, self.size), 'F', dtype='<U1')  # 'F' represents frozen surface\n",
    "        desc[self.start_point] = 'S'  # 'S' represents the starting point\n",
    "        desc[self.end_point] = 'G'    # 'G' represents the goal\n",
    "\n",
    "        # Randomly generate holes\n",
    "        hole_positions = [(i, j) for i in range(self.size) for j in range(self.size)\n",
    "                          if (i, j) not in [self.start_point, self.end_point]]\n",
    "        hole_positions = random.sample(hole_positions,self.num_holes)\n",
    "        # print(len(hole_positions))\n",
    "\n",
    "        for hole_pos in hole_positions:\n",
    "            desc[hole_pos] = 'H'  # 'H' represents a hole\n",
    "\n",
    "        # Randomly generate holes\n",
    "        special_positions = [(i, j) for i in range(self.size) for j in range(self.size)\n",
    "                          if (i, j) not in [self.start_point, self.end_point] and (i, j) not in hole_positions]\n",
    "        special_positions = random.sample(special_positions,self.num_specials)\n",
    "        # print(len(special_positions))\n",
    "\n",
    "        for special_pos in special_positions:\n",
    "            desc[special_pos] = 'R'  # 'H' represents a hole\n",
    "\n",
    "        return desc\n",
    "\n",
    "    def get_state_from_point(self, point):\n",
    "        return point[0] * self.size + point[1]\n",
    "\n",
    "    def get_point_from_state(self, state):\n",
    "        return divmod(state, self.size)\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = self.get_state_from_point(self.start_point)\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        row, col = self.get_point_from_state(self.state)\n",
    "        if action == 0:  # Move Up\n",
    "            row = max(0, row - 1)\n",
    "        elif action == 1:  # Move Down\n",
    "            row = min(self.size - 1, row + 1)\n",
    "        elif action == 2:  # Move Left\n",
    "            col = max(0, col - 1)\n",
    "        elif action == 3:  # Move Right\n",
    "            col = min(self.size - 1, col + 1)\n",
    "\n",
    "        next_state = self.get_state_from_point((row, col))\n",
    "        reward = 0\n",
    "        if self.desc[row, col] == 'G': \n",
    "            reward = 1  # +1 if the goal is reached\n",
    "        if self.desc[row, col] == 'R':\n",
    "            reward = 10  # +10 if the bonus location reached\n",
    "            self.desc[row, col] = 'F'\n",
    "        \n",
    "        done = (self.desc[row, col] == 'H') or (self.desc[row, col] == 'G')  # Done if a hole or the goal is reached\n",
    "\n",
    "        self.state = next_state\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def render(self):\n",
    "        print(\"\\n\".join([\"\".join(row) for row in self.desc]))\n",
    "        \n",
    "    def preprocess_obs(self, obs):\n",
    "        # Ensure class values are integers within the valid range\n",
    "        obs = np.clip(obs, 0, self.observation_space.n - 1)\n",
    "\n",
    "        # One-hot encoding without torch\n",
    "        obs_one_hot = np.eye(self.observation_space.n)[obs]\n",
    "\n",
    "        return obs_one_hot\n",
    "\n",
    "\n",
    "env = CustomFrozenLakeEnv(size=16, num_holes=10, num_specials=10, start_point=(0, 0), end_point=(15, 15))\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SFFFFFFFFFFFRFFF', 'FFFFFFFFFHFFFFFR', 'FFFFFFFFFFFFRFFH', 'FFFFFFFFFFFFFFFR', 'FFHFFFFFFFFFFFFF', 'FFFFFFFFFFFFFFFF', 'FFFFFFFFFFFFFFFF', 'FFFFFFRFFFFFRFFF', 'FFFFFFHFFFFFFFFF', 'FFFFFFFFFFFFFFFF', 'FFFFFFFFFFRFFFRF', 'FFFFFRFFFFFFFFFF', 'FFHFFFFHFHFHFFFF', 'FFFFFFFFFFFFFFFF', 'FFFFFFFFFHFFFFFF', 'FFFFFFHFFFRFFFFG']\n"
     ]
    }
   ],
   "source": [
    "custom_lake = [''.join(sublist) for sublist in env.desc]\n",
    "\n",
    "print(custom_lake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/software/anaconda3/envs/mlp/lib/python3.8/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 5305 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3241         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 1            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017375792 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | -0.00736     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.118        |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    value_loss           | 2.79         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2886        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008742334 |\n",
      "|    clip_fraction        | 0.0421      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.391       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 1.13        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2731        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014419438 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | -0.173      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0124     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0349     |\n",
      "|    value_loss           | 0.151       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2643        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017618125 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | -0.28       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0408     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0455     |\n",
      "|    value_loss           | 0.0736      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2578        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014118796 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | -0.0389     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.413       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 0.327       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2532        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016382609 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | -0.421      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0229     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0413     |\n",
      "|    value_loss           | 0.0362      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2504        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019125227 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.078      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0479     |\n",
      "|    value_loss           | 0.0144      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2488        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016605161 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0443     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0457     |\n",
      "|    value_loss           | 0.0151      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2474       |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 8          |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01793631 |\n",
      "|    clip_fraction        | 0.25       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.11      |\n",
      "|    explained_variance   | 0.666      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0521    |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0468    |\n",
      "|    value_loss           | 0.0155     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2461        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018549763 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.8         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0548     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0474     |\n",
      "|    value_loss           | 0.00819     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2450        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018496828 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.936      |\n",
      "|    explained_variance   | 0.814       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0639     |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0448     |\n",
      "|    value_loss           | 0.00696     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2441        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019241378 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.849      |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0455     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0364     |\n",
      "|    value_loss           | 0.00507     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2433        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015817534 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.768      |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0512     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.00406     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2430        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019196717 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.714      |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.058      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.000581    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2427        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013246101 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.661      |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0427     |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    value_loss           | 0.00326     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2425       |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 14         |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01430766 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.593     |\n",
      "|    explained_variance   | 0.75       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0186    |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0254    |\n",
      "|    value_loss           | 0.00199    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2422        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015785854 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.504      |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0378     |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    value_loss           | 0.000215    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2420       |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01687777 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.444     |\n",
      "|    explained_variance   | 0.977      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0543    |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0231    |\n",
      "|    value_loss           | 0.000118   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2417        |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007371472 |\n",
      "|    clip_fraction        | 0.0796      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.397      |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0155     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 8.02e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2413        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019679643 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.413      |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0209     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 2.48e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2409        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012626816 |\n",
      "|    clip_fraction        | 0.0963      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.415      |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0226     |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 2.02e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2407        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011594591 |\n",
      "|    clip_fraction        | 0.0936      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.402      |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000338    |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 4.41e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2405        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013475718 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.397      |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00668     |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 1.49e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2403        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009474536 |\n",
      "|    clip_fraction        | 0.0897      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.4        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0268     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 9.14e-06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2401         |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0153018115 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.42        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00564     |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.0112      |\n",
      "|    value_loss           | 1.56e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2398        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015787262 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.422      |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0443     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 5.32e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2395        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011528248 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.408      |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0442     |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 6.28e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2394        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012221137 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.398      |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0145     |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 6.54e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2391        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014972166 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.398      |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0115     |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 2.16e-06    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2386       |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 26         |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01336148 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.404     |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00546    |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0143    |\n",
      "|    value_loss           | 7.68e-06   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2385        |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017636422 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.413      |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0422     |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 4.79e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2384        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012432909 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.422      |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0313     |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 5.65e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2383        |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015060764 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.407      |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00475    |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 1.05e-06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2383         |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0108299535 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.407       |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0185      |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.0123      |\n",
      "|    value_loss           | 6.59e-06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2381        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014974911 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.414      |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0255     |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 1.28e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2379        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013804628 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.407      |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0216     |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00931    |\n",
      "|    value_loss           | 0.00294     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2377         |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 32           |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089640925 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.392       |\n",
      "|    explained_variance   | 0.857        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0222      |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.011       |\n",
      "|    value_loss           | 0.000216     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2376        |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013251985 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.405      |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0308     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 2.38e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2376        |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007949024 |\n",
      "|    clip_fraction        | 0.0668      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.401      |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00523    |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 7.47e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2375       |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 35         |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01544244 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.389     |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0314    |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0205    |\n",
      "|    value_loss           | 1.73e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2373       |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 36         |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01216248 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.386     |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.028     |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0128    |\n",
      "|    value_loss           | 2.86e-06   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2373        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017329738 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.391      |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0497     |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 1.17e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2371        |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014521708 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.384      |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0212     |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 2.15e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2366        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013575343 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.395      |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0236     |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    value_loss           | 9.47e-07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2364        |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014248015 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.399      |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0211     |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 8.79e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2363        |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013484509 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.381      |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0359     |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 3.3e-06     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2362        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011915089 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.394      |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0244     |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 0.00338     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2360        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021229576 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.399      |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0453     |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 0.000138    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/software/anaconda3/envs/mlp/lib/python3.8/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:243: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n",
      "  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "# Create and wrap the custom environment\n",
    "env = CustomFrozenLakeEnv(size=16, num_holes=10, num_specials=10, start_point=(0, 0), end_point=(15, 15))\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# Define the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=100000)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_custom_frozenlake\")\n",
    "\n",
    "# Load the trained model (optional)\n",
    "# model = PPO.load(\"ppo_custom_frozenlake\")\n",
    "\n",
    "# Test the trained agent\n",
    "obs = env.reset()\n",
    "for _ in range(1000):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, _, done, _ = env.step(action)\n",
    "    env.render()\n",
    "\n",
    "# Close the environment\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/software/anaconda3/envs/mlp/lib/python3.8/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 - Total Reward: [0.]\n",
      "Episode 2 - Total Reward: [0.]\n",
      "Episode 3 - Total Reward: [0.]\n",
      "Episode 4 - Total Reward: [0.]\n",
      "Episode 5 - Total Reward: [0.]\n",
      "Episode 6 - Total Reward: [0.]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[1;32m     34\u001b[0m     action, _states \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(obs, deterministic\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 35\u001b[0m     obs, reward, done, info \u001b[39m=\u001b[39m vec_env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     37\u001b[0m     \u001b[39m# Store observations, actions, and rewards during the episode\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     episode_path[\u001b[39m\"\u001b[39m\u001b[39mobservations\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(obs\u001b[39m.\u001b[39mcopy())\n",
      "File \u001b[0;32m~/anaconda3/envs/mlp/lib/python3.8/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[39m:param actions: the action\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[39m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 206\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/mlp/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_wait\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     56\u001b[0m     \u001b[39m# Avoid circular imports\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[39mfor\u001b[39;00m env_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_envs):\n\u001b[0;32m---> 58\u001b[0m         obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menvs[env_idx]\u001b[39m.\u001b[39;49mstep(\n\u001b[1;32m     59\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactions[env_idx]\n\u001b[1;32m     60\u001b[0m         )\n\u001b[1;32m     61\u001b[0m         \u001b[39m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx] \u001b[39m=\u001b[39m terminated \u001b[39mor\u001b[39;00m truncated\n",
      "File \u001b[0;32m~/anaconda3/envs/mlp/lib/python3.8/site-packages/shimmy/openai_gym_compatibility.py:117\u001b[0m, in \u001b[0;36mGymV26CompatibilityV0.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action: ActType) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m[ObsType, \u001b[39mfloat\u001b[39m, \u001b[39mbool\u001b[39m, \u001b[39mbool\u001b[39m, \u001b[39mdict\u001b[39m]:\n\u001b[1;32m    109\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Steps through the environment.\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \n\u001b[1;32m    111\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39m        (observation, reward, terminated, truncated, info)\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgym_env\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlp/lib/python3.8/site-packages/gym/wrappers/time_limit.py:50\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[1;32m     40\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[0;32m~/anaconda3/envs/mlp/lib/python3.8/site-packages/gym/wrappers/order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[1;32m     36\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling env.reset()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlp/lib/python3.8/site-packages/gym/wrappers/env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m env_step_passive_checker(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv, action)\n\u001b[1;32m     38\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlp/lib/python3.8/site-packages/gym/envs/toy_text/frozen_lake.py:252\u001b[0m, in \u001b[0;36mFrozenLakeEnv.step\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlastaction \u001b[39m=\u001b[39m a\n\u001b[1;32m    251\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 252\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrender()\n\u001b[1;32m    253\u001b[0m \u001b[39mreturn\u001b[39;00m (\u001b[39mint\u001b[39m(s), r, t, \u001b[39mFalse\u001b[39;00m, {\u001b[39m\"\u001b[39m\u001b[39mprob\u001b[39m\u001b[39m\"\u001b[39m: p})\n",
      "File \u001b[0;32m~/anaconda3/envs/mlp/lib/python3.8/site-packages/gym/envs/toy_text/frozen_lake.py:279\u001b[0m, in \u001b[0;36mFrozenLakeEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_render_text()\n\u001b[1;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# self.render_mode in {\"human\", \"rgb_array\"}:\u001b[39;00m\n\u001b[0;32m--> 279\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_render_gui(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrender_mode)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlp/lib/python3.8/site-packages/gym/envs/toy_text/frozen_lake.py:373\u001b[0m, in \u001b[0;36mFrozenLakeEnv._render_gui\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    371\u001b[0m     pygame\u001b[39m.\u001b[39mevent\u001b[39m.\u001b[39mpump()\n\u001b[1;32m    372\u001b[0m     pygame\u001b[39m.\u001b[39mdisplay\u001b[39m.\u001b[39mupdate()\n\u001b[0;32m--> 373\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclock\u001b[39m.\u001b[39;49mtick(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetadata[\u001b[39m\"\u001b[39;49m\u001b[39mrender_fps\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    374\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrgb_array\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    375\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mtranspose(\n\u001b[1;32m    376\u001b[0m         np\u001b[39m.\u001b[39marray(pygame\u001b[39m.\u001b[39msurfarray\u001b[39m.\u001b[39mpixels3d(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_surface)), axes\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m    377\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from level2 import CustomFrozenLakeEnv\n",
    "\n",
    "environment_name = 'FrozenLake-v1'\n",
    "render_mode = 'human'\n",
    "\n",
    "try:\n",
    "    gym_env = gym.make(environment_name, desc=custom_lake, render_mode=render_mode)\n",
    "    vec_env = DummyVecEnv([lambda: gym_env])\n",
    "except gym.error.UnregisteredEnv:\n",
    "    # If the Gymnasium environment is not available, use the OpenAI Gym environment\n",
    "    vec_env = DummyVecEnv([lambda: gym.make(environment_name, desc=custom_lake, render_mode=render_mode)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the trained model\n",
    "model = PPO.load(\"/Users/software/Desktop/reinforcement_learning_practise/hackathon/level_1/level3_custom_frozenlake_model.zip\")\n",
    "\n",
    "# Set the number of episodes for the trial\n",
    "num_episodes = 50\n",
    "\n",
    "# Run a trial of various episodes\n",
    "for episode in range(num_episodes):\n",
    "    obs = vec_env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    episode_path = {\"observations\": [], \"actions\": [], \"rewards\": []}\n",
    "\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = vec_env.step(action)\n",
    "\n",
    "        # Store observations, actions, and rewards during the episode\n",
    "        episode_path[\"observations\"].append(obs.copy())\n",
    "        episode_path[\"actions\"].append(action)\n",
    "        episode_path[\"rewards\"].append(reward)\n",
    "\n",
    "        total_reward += reward\n",
    "\n",
    "    print(f\"Episode {episode + 1} - Total Reward: {total_reward}\")\n",
    "\n",
    "    # Check if the episode was successful\n",
    "    if total_reward == 1:\n",
    "        print(\"Episode succeeded!\")\n",
    "        print(\"Observations:\", episode_path[\"observations\"])\n",
    "        print(\"Actions:\", episode_path[\"actions\"])\n",
    "        print(\"Rewards:\", episode_path[\"rewards\"])\n",
    "\n",
    "# Close the environment\n",
    "vec_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
